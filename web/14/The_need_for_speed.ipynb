{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 14: The Need for Speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Download on GitHub](https://github.com/NumEconCopenhagen/lectures-2021)\n",
    "\n",
    "[<img src=\"https://mybinder.org/badge_logo.svg\">](https://mybinder.org/v2/gh/NumEconCopenhagen/lectures-2021/master?urlpath=lab/tree/14/The_need_for_speed.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Computers](#Computers)\n",
    "2. [Timing and precomputations](#Timing-and-precomputations)\n",
    "3. [List comprehensions are your friend](#List-comprehensions-are-your-friend)\n",
    "4. [Optimizing Numpy](#Optimizing-Numpy)\n",
    "5. [Numba](#Numba)\n",
    "6. [Parallization without Numba](#Parallization-without-Numba)\n",
    "7. [Pandas](#Pandas)\n",
    "8. [Summary](#Summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will learn how to time your code and locate its bottlenecks. You will learn how to alleviate such bottlenecks using techniques such as **comprehensions**, **generators**, **vectorization** and **parallelization**. You will be introduced to how  to use the **Numba** library to speed-up your code. You will hear about the fundamental computational costs of mathematical operations and memory management (caching)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import optimize\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# performance libraries\n",
    "import numba as nb\n",
    "import joblib # conda install joblib\n",
    "import dask # conda install dask\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# magics\n",
    "#  conda install line_profiler\n",
    "#  conda install memory_profiler\n",
    "\n",
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler\n",
    "\n",
    "# local module\n",
    "import needforspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this computer has 8 CPUs\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "CPUs = psutil.cpu_count()\n",
    "CPUs_list = set(np.sort([1,2,4,*np.arange(8,CPUs+1,4)])) \n",
    "print(f'this computer has {CPUs} CPUs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Computers\"></a>\n",
    "\n",
    "# 1. Computers\n",
    "\n",
    "We can represent a **computer** in a simplified diagram as:\n",
    "\n",
    "<img src=\"https://github.com/NumEconCopenhagen/lectures-2019/raw/master/11/computer.gif\" alt=\"computer\" width=60% />\n",
    "\n",
    "**Performance goals:**\n",
    "\n",
    "1. Minimize the number of logical and algebraic operations ([details](https://streamhpc.com/blog/2012-07-16/how-expensive-is-an-operation-on-a-cpu/))\n",
    "2. Minimize the number of times new memory needs to be allocated (and the amount)\n",
    "3. Minimize the number of read and write memory (and especially storage) operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizing your code for **optimal performance is a very very complicated task**. When using Python a lot of stuff is happening *under the hood*, which you don't control. \n",
    "\n",
    "* Python is an **interpreted** language; each line of Python code is converted into machine code at runtime when the line is reached. Error checks and memory management are performed automatically.\n",
    "* Faster languages (C/C++, Fortran) are **compiled** to machine code before the program is run $\\rightarrow$ faster, but you are required to specify e.g. types of variables beforehand. Error checks and memory management must be performed manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Often overlooked**, todays CPUs are so fast that feeding them data quickly enough can be a serious bottleneck."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modern CPUs** can do a lot of smart, complicated, stuff.\n",
    "\n",
    "> **Single-instruction multiply data (SIMD):** The computional cost of multiplying one float with another is the same as multiplying e.g. vectors of 4 doubles at once (or 8 doubles if you have AVX-512).\n",
    "\n",
    "> **Out-of-order execution:** If you tell the computer to\n",
    "> \n",
    "> 1. read data ``X``\n",
    "> 2. run ``f(X)``\n",
    "> 3. read data ``Y``\n",
    "> 4. run ``g(Y)``\n",
    ">\n",
    "> then it might try to do step 2 and step 3 simultanously because they use different parts of the CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Caching:** Let ``x`` be a one-dimensional numpy array, and assume you read the value in ``x[i]`` and then read the value in ``x[j]``. If ``j`` is \"close\" to ``i`` then the value of ``x[j]`` will already be in the *cache* and the second read operation will be faster (almost instantanous)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parallization:** Modern computers have multiple CPUs (or even other computing units such as GPUs). This is to some degree used implicitely by e.g. built-in Numpy and Scipy functions, but we also discuss how to do this manually later in this lecture. The clock speed of each CPU has stopped increasing for technical reasons, the number of transistors on each chip continue to increase exponentially (**Moore's Law**) due to more CPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/NumEconCopenhagen/lectures-2019/raw/master/11/moores_law.png\" alt=\"moores_law\" width=80% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Memory:** We have many different kinds of memory\n",
    "\n",
    "1. Cache\n",
    "2. RAM (Random Access Memory)\n",
    "3. Hard drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We control what is in the **RAM** and on the the **hard drive**; the latter is a lot slower than the former. The cache is used by the computer under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/NumEconCopenhagen/lectures-2019/raw/master/11/memory.gif\" alt=\"memory\" width=40% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Three important principles:**\n",
    "\n",
    "1. **Use built-in features** of Python, Numpy, Scipy etc. whenever possible (often use fast compiled code).\n",
    "2. **Ordered operations** is better than random operations.\n",
    "3. **\"Premature optimization is the root of all evil\"** (Donald Knuth). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a **trade-off** between **human time** (the time it takes to write the code) and **computer time** (the time it takes to run the code)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Timing-and-precomputations\"></a>\n",
    "\n",
    "# 2. Timing and precomputations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following function doing some simple algebraic operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfun(x,i):\n",
    "    y = 0\n",
    "    for j in range(100):\n",
    "        y += x**j\n",
    "    return y + i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And another function calling the former function in a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfun_loop(n):\n",
    "    mysum = 0\n",
    "    for i in range(n):\n",
    "        mysum += myfun(5,i)\n",
    "    return mysum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How long does it take to run ``myfun_loop``:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A.** Manual timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11831427 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "mysum = myfun_loop(1000)\n",
    "t1 = time.time()    \n",
    "print(f'{t1-t0:.8} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B.** Use the ``%time`` magic (work on a single line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 127 ms\n",
      "Wall time: 112 ms\n"
     ]
    }
   ],
   "source": [
    "%time mysum = myfun_loop(1000)\n",
    "%time mysum = myfun_loop(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **ms** $\\equiv$ milliseconds, $10^{-3}$ of a second.<br>\n",
    "> **$\\mu$s** $\\equiv$ mikroseconds, $10^{-6}$ of a second.<br>\n",
    "> **ns** $\\equiv$ nanoseconds, $10^{-9}$ of a second."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C.** Use the ``%timeit`` magic to also see variability (work on single line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.4 ms ± 18.3 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "59.1 ms ± 3.99 ms per loop (mean ± std. dev. of 5 runs, 20 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit myfun_loop(1000)\n",
    "%timeit -r 5 -n 20 myfun_loop(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ``%timeit`` report the best of ``r`` runs each calling the code ``n`` times in a loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D.** Use the ``%%time`` magic (work on a whole cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 55.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1972152263052529513529321413206965574183016087772557511925697326660655500"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "n = 1000\n",
    "myfun_loop(n);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E.** Use the ``%%timeit`` magic to also see variabilty (work on a whole cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.8 ms ± 25 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "n = 1000\n",
    "myfun_loop(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How can we speed up the computation using **precomputation**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfun_loop_fast(n):\n",
    "    myfunx = myfun(5,0)\n",
    "    mysum = 0\n",
    "    for i in range(n):\n",
    "        mysum = myfunx+i\n",
    "    return mysum\n",
    "    \n",
    "# remember\n",
    "def myfun_loop(n):\n",
    "    mysum = 0\n",
    "    for i in range(n):\n",
    "        mysum += myfun(5,i)\n",
    "    return mysum\n",
    "\n",
    "def myfun(x,i):\n",
    "    y = 0\n",
    "    for j in range(100):\n",
    "        y += x**j\n",
    "    return y + i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def myfun_loop_fast(n):\n",
    "    myfunx = myfun(5,0) # precomputation\n",
    "    mysum = 0\n",
    "    for i in range(n):\n",
    "        mysum += myfunx + i\n",
    "    return mysum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00000000 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "mysum_fast = myfun_loop_fast(1000)\n",
    "t1 = time.time()    \n",
    "print(f'{t1-t0:.8f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too fast to be measured with ``time.time()``. The ``%timeit`` magic still works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.3 ms ± 4.8 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "173 µs ± 41.6 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit myfun_loop(1000)\n",
    "%timeit myfun_loop_fast(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\rightarrow$ **orders of magnitude faster!**\n",
    "\n",
    "Check the **results are the same**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert mysum == mysum_fast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Premature optimization is the root of all evil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important:** Before deciding whether to do a precomputation (which often makes the code harder to read) we should investigate, whether it alleviates a bottleneck.\n",
    "\n",
    "* **A.** Insert multiple ``time.time()`` to time different parts of the code.\n",
    "* **B.** Use the ``line_profiler`` with syntax (also works with methods for classes)\n",
    "\n",
    "  ``%lprun -f FUNCTION_TO_PROFILE -f FUNCTION_TO_PROFILE FUNCTION_TO_RUN``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline method:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 5.40083e-07 s\n",
       "\n",
       "Total time: 0.175563 s\n",
       "File: <ipython-input-10-8eb286437082>\n",
       "Function: myfun_loop at line 9\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     9                                           def myfun_loop(n):\n",
       "    10         1         14.0     14.0      0.0      mysum = 0\n",
       "    11      1001        682.0      0.7      0.2      for i in range(n):\n",
       "    12      1000     324370.0    324.4     99.8          mysum += myfun(5,i)\n",
       "    13         1          1.0      1.0      0.0      return mysum\n",
       "\n",
       "Total time: 0.121627 s\n",
       "File: <ipython-input-10-8eb286437082>\n",
       "Function: myfun at line 15\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    15                                           def myfun(x,i):\n",
       "    16      1000        703.0      0.7      0.3      y = 0\n",
       "    17    101000      60384.0      0.6     26.8      for j in range(100):\n",
       "    18    100000     163314.0      1.6     72.5          y += x**j\n",
       "    19      1000        799.0      0.8      0.4      return y + i"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f myfun -f myfun_loop myfun_loop(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** Most of the time is spend in ``myfun()``, more specifically the computation of the power in line 4. The precomputation solves this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare with the fast method:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 5.40083e-07 s\n",
       "\n",
       "Total time: 0.000895457 s\n",
       "File: <ipython-input-11-71ad68e510eb>\n",
       "Function: myfun_loop_fast at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def myfun_loop_fast(n):\n",
       "     2         1        190.0    190.0     11.5      myfunx = myfun(5,0) # precomputation\n",
       "     3         1          1.0      1.0      0.1      mysum = 0\n",
       "     4      1001        611.0      0.6     36.9      for i in range(n):\n",
       "     5      1000        855.0      0.9     51.6          mysum += myfunx + i\n",
       "     6         1          1.0      1.0      0.1      return mysum"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f myfun_loop_fast myfun_loop_fast(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"List-comprehensions-are-your-friend\"></a>\n",
    "\n",
    "# 3. List comprehensions are your friend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the first $n$ squares using a **loop**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squares(n):\n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        result.append(i*i)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or in a **list comprehension**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squares_comprehension(n):\n",
    "    return [i*i for i in range(n)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They give the **same result**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "mylist = squares(n)\n",
    "mylist_fast = squares_comprehension(n)\n",
    "assert mylist == mylist_fast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the **list comphrension is faster**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.6 µs ± 6.6 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "83.9 µs ± 9.59 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit mylist = squares(n)\n",
    "%timeit mylist_fast = squares_comprehension(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Why is this slower?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442 µs ± 23.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit [i**2 for i in range(1,n+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume you are only interested in the **sum of the squares**. Can be calculated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "squares_list = [i*i for i in range(n)]\n",
    "mysum = 0\n",
    "for square in squares_list:\n",
    "    mysum += square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** In line 1 we create the full list even though we only need one element at a time<br>\n",
    "$\\rightarrow $ *we allocate memory we need not allocate.*\n",
    "\n",
    "**Solution:** Can be avoided with a **generator**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "squares_generator = (i*i for i in range(n)) # notice: parentheses instead of brackets\n",
    "mysum_gen = 0\n",
    "for square in squares_generator:\n",
    "    mysum_gen += square\n",
    "\n",
    "assert mysum == mysum_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **memory footprint** can be investigated with the **memory_profiler** with syntax\n",
    "\n",
    "``%mprun -f FUNCTION_TO_PROFILE -f FUNCTION_TO_PROFILE FUNCTION_TO_RUN``\n",
    "\n",
    "**Caveat:** Needs to be a function in an external module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Filename: C:\\Users\\gmf123\\Dropbox\\NumEconCopenhagen\\lectures-2020\\12\\needforspeed.py\n",
       "\n",
       "Line #    Mem usage    Increment   Line Contents\n",
       "================================================\n",
       "     9    157.1 MiB    157.1 MiB   def test_memory(n):\n",
       "    10                             \n",
       "    11                                 # list vs. generators\n",
       "    12    195.9 MiB     38.8 MiB       squares = create_list(n)\n",
       "    13    195.9 MiB      0.0 MiB       squares_generator = create_generator(n)\n",
       "    14                             \n",
       "    15                                 # numpy arrays of different types\n",
       "    16    203.6 MiB      7.6 MiB       A = np.ones((1000,1000))\n",
       "    17    211.2 MiB      7.6 MiB       B = np.ones((1000,1000),dtype=np.double)\n",
       "    18    215.0 MiB      3.8 MiB       C = np.ones((1000,1000),dtype=np.single)\n",
       "    19    222.6 MiB      7.6 MiB       D = np.ones((1000,1000),dtype=np.int64)\n",
       "    20    226.5 MiB      3.8 MiB       E = np.ones((1000,1000),dtype=np.int32)\n",
       "    21    227.4 MiB      1.0 MiB       F = np.ones((1000,1000),dtype=np.bool)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%mprun -f needforspeed.test_memory needforspeed.test_memory(10**6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **MiB** 1 MiB = 1.048576 MB\n",
    ">\n",
    "> **Numpy:** Note how you can save memory by specifying the data type for the numpy array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternative:** Generators can also be created as functions with a ``yield`` instead of a ``return`` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_func(n):\n",
    "    for i in range(n):\n",
    "        yield i*i\n",
    "\n",
    "squares_generator = f_func(n)\n",
    "mysum_gen = 0\n",
    "for square in squares_generator:\n",
    "    mysum_gen += square\n",
    "\n",
    "assert mysum == mysum_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Details on generators (+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As everything else in Python **a generator is just a special kind of class**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class f_class():\n",
    "    \n",
    "    def __init__(self,n):    \n",
    "        self.i = 0\n",
    "        self.n = n\n",
    "    \n",
    "    def __iter__(self):\n",
    "        # print('calling __iter__')\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        # print('calling __iter__')\n",
    "        if self.i < self.n:\n",
    "            cur = self.i*self.i\n",
    "            self.i += 1\n",
    "            return cur\n",
    "        else:\n",
    "            raise StopIteration()\n",
    "    \n",
    "squares_generator = f_class(n)\n",
    "mysum_gen = 0\n",
    "for square in squares_generator:\n",
    "    mysum_gen += square\n",
    "\n",
    "assert mysum == mysum_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** ``for x in vec`` first calls ``iter`` on vec and then ``next`` repeatly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "4\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "squares_generator = iter(f_class(n))\n",
    "print(next(squares_generator))\n",
    "print(next(squares_generator))\n",
    "print(next(squares_generator))\n",
    "print(next(squares_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Illustrative example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first run\n",
      "1\n",
      "running again\n",
      "9\n",
      "running again again\n",
      "4\n",
      "no more values to yield\n"
     ]
    }
   ],
   "source": [
    "def g():\n",
    "    print('first run')\n",
    "    yield 1\n",
    "    print('running again')\n",
    "    yield 9\n",
    "    print('running again again')\n",
    "    yield 4\n",
    "    \n",
    "mygen = iter(g())\n",
    "print(next(mygen))\n",
    "print(next(mygen))\n",
    "print(next(mygen))\n",
    "try:\n",
    "    print(next(mygen))\n",
    "except:\n",
    "    print('no more values to yield')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first run\n",
      "1\n",
      "running again\n",
      "9\n",
      "running again again\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for x in g():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Optimizing-Numpy\"></a>\n",
    "\n",
    "# 4. Optimizing Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Tip 1: Always use vectorized operations when available\n",
    "\n",
    "**Simple comparison:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318 ms ± 26.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "349 ms ± 66.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.53 ms ± 222 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.uniform(size=500000)\n",
    "\n",
    "def python_add(x):\n",
    "    y = []\n",
    "    for xi in x:\n",
    "        y.append(xi+1)\n",
    "    return y\n",
    "\n",
    "def numpy_add(x):\n",
    "    y = np.empty(x.size)\n",
    "    for i in range(x.size):\n",
    "        y[i] = x[i]+1\n",
    "    return y\n",
    "\n",
    "def numpy_add_vec(x):\n",
    "    return x+1\n",
    "\n",
    "assert np.allclose(python_add(x),numpy_add(x))\n",
    "assert np.allclose(python_add(x),numpy_add_vec(x))\n",
    "\n",
    "%timeit python_add(x)\n",
    "%timeit numpy_add(x)\n",
    "%timeit numpy_add_vec(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even **stronger** when the **computation is more complicated:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "951 ms ± 131 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "961 ms ± 201 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "5.91 ms ± 1.17 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "def python_exp(x):\n",
    "    y = []\n",
    "    for xi in x:\n",
    "        y.append(np.exp(xi))\n",
    "    return y\n",
    "\n",
    "def numpy_exp(x):\n",
    "    y = np.empty(x.size)\n",
    "    for i in range(x.size):\n",
    "        y[i] = np.exp(x[i])\n",
    "    return y\n",
    "\n",
    "def numpy_exp_vec(x):\n",
    "    return np.exp(x)\n",
    "\n",
    "assert np.allclose(python_exp(x),numpy_exp(x))\n",
    "assert np.allclose(python_exp(x),numpy_exp_vec(x))\n",
    "\n",
    "%timeit python_exp(x)\n",
    "%timeit numpy_exp(x)\n",
    "%timeit numpy_exp_vec(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also works for a **conditional sum**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381 ms ± 12.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "6.63 ms ± 561 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "8.43 ms ± 671 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "def python_exp_cond(x):\n",
    "    return [np.exp(xi) for xi in x if xi < 0.5]\n",
    "\n",
    "def numpy_exp_vec_cond(x):\n",
    "    y = np.exp(x[x < 0.5])\n",
    "    return y\n",
    "\n",
    "def numpy_exp_vec_cond_alt(x):\n",
    "    y = np.exp(x)[x < 0.5]\n",
    "    return y\n",
    "\n",
    "assert np.allclose(python_exp_cond(x),numpy_exp_vec_cond(x))\n",
    "assert np.allclose(python_exp_cond(x),numpy_exp_vec_cond_alt(x))\n",
    "\n",
    "%timeit python_exp_cond(x)\n",
    "%timeit numpy_exp_vec_cond(x)\n",
    "%timeit numpy_exp_vec_cond_alt(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Why do you think the speed-up is less pronounced in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Tip 2: Operations are faster on rows than on columns\n",
    "\n",
    "Generally, operate on the **outermost index**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.4 ms ± 929 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "18.8 ms ± 761 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "x = np.random.uniform(size=(n,n))\n",
    "\n",
    "def add_rowsums(x):\n",
    "    mysum = 0\n",
    "    for i in range(x.shape[0]):\n",
    "        mysum += np.sum(np.exp(x[i,:]))\n",
    "    return mysum\n",
    "            \n",
    "def add_colsums(x):\n",
    "    mysum = 0\n",
    "    for j in range(x.shape[1]):\n",
    "        mysum += np.sum(np.exp(x[:,j]))\n",
    "    return mysum\n",
    "\n",
    "assert np.allclose(add_rowsums(x),add_colsums(x))\n",
    "            \n",
    "%timeit add_rowsums(x)\n",
    "%timeit add_colsums(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/NumEconCopenhagen/lectures-2019/raw/master/11/numpy_memory_layout.png\" alt=\"amdahls_law\" width=60% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **memory structure can be changed manually** so that working on columns (innermost index) is better than working on rows (outermost index):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.1 ms ± 764 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "14.5 ms ± 2.38 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "y = np.array(x,order='F') # the default is order='C'\n",
    "%timeit add_rowsums(y)\n",
    "%timeit add_colsums(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Tip 3: Also use vectorized operations when it is a bit cumbersome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the task of calculating the following **expected value**:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "W(a)&=\\mathbb{E}\\left[\\sqrt{\\frac{a}{\\psi}+\\xi}\\right]\\\\\n",
    "\\psi,\\xi&\\in \\begin{cases}\n",
    "0.25 & \\text{with prob. }0.25\\\\\n",
    "0.5 & \\text{with prob. }0.25\\\\\n",
    "1.5 & \\text{with prob. }0.25\\\\\n",
    "1.75 & \\text{with prob. }0.25\n",
    "\\end{cases}\\end{aligned}\n",
    "$$\n",
    "\n",
    "for a vector of $a$-values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5000\n",
    "a_vec = np.linspace(0,10,N)\n",
    "\n",
    "xi_vec = np.array([0.25,0.5,1.5,1.75])\n",
    "psi_vec = np.array([0.25,0.5,1.5,1.75])\n",
    "\n",
    "xi_w_vec = np.ones(4)/4\n",
    "psi_w_vec = np.ones(4)/4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loop based solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208 ms ± 7.15 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def loop(a_vec,xi_vec,psi_vec,xi_w_vec,psi_w_vec):\n",
    "    \n",
    "    w_vec = np.zeros(a_vec.size)\n",
    "    for i,a in enumerate(a_vec):        \n",
    "        for xi,xi_w in zip(xi_vec,xi_w_vec):\n",
    "            for psi,psi_w in zip(psi_vec,psi_w_vec):\n",
    "                m_plus = a/psi + xi\n",
    "                v_plus = np.sqrt(m_plus)\n",
    "                w_vec[i] += xi_w*psi_w*v_plus\n",
    "    \n",
    "    return w_vec\n",
    "        \n",
    "loop_result = loop(a_vec,xi_vec,psi_vec,xi_w_vec,psi_w_vec)  \n",
    "%timeit loop(a_vec,xi_vec,psi_vec,xi_w_vec,psi_w_vec)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare vectorized solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.5 µs ± 1.47 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def prep_vec(a_vec,xi_vec,psi_vec,xi_w_vec,psi_w_vec):\n",
    "    \n",
    "    # a. make a (1,N) instead of (N,)\n",
    "    a = a_vec.reshape((1,N))\n",
    "    \n",
    "    # b. make xi and psi to be (xi.size*psi.size,1) vectors\n",
    "    xi,psi = np.meshgrid(xi_vec,psi_vec)     \n",
    "    xi = xi.reshape((xi.size,1))\n",
    "    psi = psi.reshape((psi.size,1))\n",
    "    \n",
    "    # c. make xi and psi to be (xi.size*psi.size,1) vectors    \n",
    "    xi_w,psi_w = np.meshgrid(xi_w_vec,psi_w_vec)     \n",
    "    xi_w = xi_w.reshape((xi_w.size,1))\n",
    "    psi_w = psi_w.reshape((psi_w.size,1))\n",
    "    \n",
    "    return a,xi,psi,xi_w,psi_w\n",
    "\n",
    "a,xi,psi,xi_w,psi_w = prep_vec(a_vec,xi_vec,psi_vec,xi_w_vec,psi_w_vec)\n",
    "%timeit prep_vec(a,xi,psi_vec,xi_w_vec,psi_w_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply vectorized solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328 µs ± 55.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def vec(a,xi,psi,xi_w,psi_w):   \n",
    "    m_plus_vec = a/psi + xi # use broadcasting, m_plus_vec.shape = (xi.size*psi.size,N)\n",
    "    v_plus_vec = np.sqrt(m_plus_vec) # vectorized funciton call\n",
    "    w_mat = xi_w*psi_w*v_plus_vec\n",
    "    w_vec = np.sum(w_mat,axis=0) # sum over rows\n",
    "    return w_vec\n",
    "\n",
    "vec_result = vec(a,psi,xi,xi_w,psi_w)\n",
    "assert np.allclose(loop_result,vec_result)\n",
    "%timeit vec(a,psi,xi,xi_w,psi_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** Much much faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply vectorized solution without preperation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "735 µs ± 70.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def vec(a,xi,psi,xi_w,psi_w):   \n",
    "    m_plus_vec = a[:,np.newaxis,np.newaxis]/psi[np.newaxis,:,np.newaxis] + xi[np.newaxis,np.newaxis,:]\n",
    "    v_plus_vec = np.sqrt(m_plus_vec)\n",
    "    w_mat = xi_w[np.newaxis,np.newaxis,:]*psi_w[np.newaxis,:,np.newaxis]*v_plus_vec\n",
    "    w_vec = np.sum(w_mat,axis=(1,2))\n",
    "    return w_vec\n",
    "\n",
    "vec_result_noprep = vec(a_vec,psi_vec,xi_vec,xi_w_vec,psi_w_vec)\n",
    "assert np.allclose(loop_result,vec_result_noprep)\n",
    "%timeit vec(a_vec,psi_vec,xi_vec,xi_w_vec,psi_w_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Numba\"></a>\n",
    "\n",
    "# 5. Numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing **vectorized code can be cumbersome**, and in some cases it is impossible. Instead we can use the **numba** module. \n",
    "\n",
    "Adding the decorator `nb.njit` on top of a function tells numba to compile this function **to machine code just-in-time**. This takes some time when the function is called the first time, but subsequent calls are then a lot faster. *The input types can, however, not change between calls because numba infer them on the first call.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.85 s ± 269 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def myfun_numpy_vec(x1,x2):\n",
    "    y = np.empty((1,x1.size))\n",
    "    I = x1 < 0.5\n",
    "    y[I] = np.sum(np.exp(x2*x1[I]),axis=0)\n",
    "    y[~I] = np.sum(np.log(x2*x1[~I]),axis=0)\n",
    "    return y\n",
    "\n",
    "# setup\n",
    "x1 = np.random.uniform(size=10**6)\n",
    "x2 = np.random.uniform(size=np.int(100*CPUs/8)) # adjust the size of the problem\n",
    "x1_np = x1.reshape((1,x1.size))\n",
    "x2_np = x2.reshape((x2.size,1))\n",
    "\n",
    "# timing\n",
    "%timeit myfun_numpy_vec(x1_np,x2_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numba:** The first call is slower, but the result is the same, and the subsequent calls are faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.17 s\n",
      "510 ms ± 28.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "@nb.njit\n",
    "def myfun_numba(x1,x2):\n",
    "    y = np.empty(x1.size)\n",
    "    for i in range(x1.size):\n",
    "        if x1[i] < 0.5:\n",
    "            y[i] = np.sum(np.exp(x2*x1[i]))\n",
    "        else:\n",
    "            y[i] = np.sum(np.log(x2*x1[i]))\n",
    "    return y\n",
    "\n",
    "# call to just-in-time compile\n",
    "%time myfun_numba(x1,x2)\n",
    "\n",
    "# actual measurement\n",
    "%timeit myfun_numba(x1,x2)\n",
    "\n",
    "assert np.allclose(myfun_numpy_vec(x1_np,x2_np),myfun_numba(x1,x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Further speed up:** Use\n",
    "\n",
    "1. parallelization (with ``prange``), and \n",
    "2. faster but less precise math (with ``fastmath``)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239 ms ± 6.29 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "@nb.njit(parallel=True)\n",
    "def myfun_numba_par(x1,x2):\n",
    "    y = np.empty(x1.size)\n",
    "    for i in nb.prange(x1.size): # in parallel across threads\n",
    "        if x1[i] < 0.5:\n",
    "            y[i] = np.sum(np.exp(x2*x1[i]))\n",
    "        else:\n",
    "            y[i] = np.sum(np.log(x2*x1[i]))\n",
    "    return y\n",
    "\n",
    "assert np.allclose(myfun_numpy_vec(x1_np,x2_np),myfun_numba_par(x1,x2))\n",
    "%timeit myfun_numba_par(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.7 ms ± 2.87 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "@nb.njit(parallel=True,fastmath=True)\n",
    "def myfun_numba_par_fast(x1,x2):\n",
    "    y = np.empty(x1.size)\n",
    "    for i in nb.prange(x1.size): # in parallel across threads\n",
    "        if x1[i] < 0.5:\n",
    "            y[i] = np.sum(np.exp(x2*x1[i]))\n",
    "        else:\n",
    "            y[i] = np.sum(np.log(x2*x1[i]))\n",
    "    return y\n",
    "\n",
    "assert np.allclose(myfun_numpy_vec(x1_np,x2_np),myfun_numba_par_fast(x1,x2))\n",
    "%timeit myfun_numba_par_fast(x1,x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Caveats:** Only a limited number of Python and Numpy features are supported inside just-in-time compiled functions.\n",
    "\n",
    "- [Supported Python features](https://numba.pydata.org/numba-doc/dev/reference/pysupported.html)\n",
    "- [Supported Numpy features](https://numba.pydata.org/numba-doc/dev/reference/numpysupported.html)\n",
    "\n",
    "**Parallization** can not always be used. Some problems are inherently sequential. If the result from a previous iteration of the loop is required in a later iteration, the cannot be executed seperately in parallel (except in some special cases such as summing). The larger the proportion of the code, which can be run in parallel is, the larger the potential speed-up is. This is called **Amdahl's Law**.\n",
    "\n",
    "<img src=\"https://github.com/NumEconCopenhagen/lectures-2019/raw/master/11/amdahls_law.png\" alt=\"amdahls_law\" width=40% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Parallization-without-Numba\"></a>\n",
    "\n",
    "# 6. Parallization without Numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 serial problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume we need to **solve the following optimization problem**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solver(alpha,beta,gamma):\n",
    "    return optimize.minimize(lambda x: (x[0]-alpha)**2 + \n",
    "                                       (x[1]-beta)**2 + \n",
    "                                       (x[2]-gamma)**2,[0,0,0],method='nelder-mead')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$n$ times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.37 s\n"
     ]
    }
   ],
   "source": [
    "n = 100*CPUs\n",
    "alphas = np.random.uniform(size=n)\n",
    "betas = np.random.uniform(size=n)\n",
    "gammas = np.random.uniform(size=n)\n",
    "\n",
    "def serial_solver(alphas,betas,gammas):\n",
    "    results = [solver(alpha,beta,gamma) for (alpha,beta,gamma) in zip(alphas,betas,gammas)]\n",
    "    return [result.x for result in results]\n",
    "\n",
    "%time xopts = serial_solver(alphas,betas,gammas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numba:** Numba can *not* be used for parallization here because we rely on the non-Numba function ``scipy.optimize.minimize``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Joblib** can be used to run python code in **parallel**.\n",
    "\n",
    "1. ``joblib.delayed(FUNC)(ARGS)`` create a task to call  ``FUNC`` with ``ARGS``.\n",
    "2. ``joblib.Parallel(n_jobs=K)(TASKS)`` execute the tasks in ``TASKS`` in ``K`` parallel processes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_jobs = 8\n",
      "Wall time: 3.15 s\n",
      "\n",
      "n_jobs = 1\n",
      "Wall time: 3.41 s\n",
      "\n",
      "n_jobs = 2\n",
      "Wall time: 2.94 s\n",
      "\n",
      "n_jobs = 4\n",
      "Wall time: 2.57 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def parallel_solver_joblib(alphas,betas,gammas,n_jobs=1):\n",
    "\n",
    "    tasks = (joblib.delayed(solver)(alpha,beta,gamma) for (alpha,beta,gamma) in zip(alphas,betas,gammas))\n",
    "    results = joblib.Parallel(n_jobs=n_jobs)(tasks)\n",
    "    \n",
    "    return [result.x for result in results]\n",
    "    \n",
    "for n_jobs in CPUs_list:\n",
    "    if n_jobs > 36: break\n",
    "    print(f'n_jobs = {n_jobs}')\n",
    "    %time xopts = parallel_solver_joblib(alphas,betas,gammas,n_jobs=n_jobs)\n",
    "    print(f'')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drawback:** The inputs to the functions are serialized and copied to each parallel process.\n",
    "\n",
    "[More on Joblib](https://joblib.readthedocs.io/en/latest/index.html) ([examples](https://joblib.readthedocs.io/en/latest/parallel.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What happens if you remove the ``method=nelder-mead`` in the ``solver()`` function? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 dask (+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dask can also be used to run python code in **parallel**.\n",
    "\n",
    "1. ``dask.delayed(FUNCS)(ARGS)`` create a task to call  ``FUNC`` with ``ARGS``.\n",
    "2. ``dask.compute(TASKS,scheduler='processes',num_workers=K)`` execute the tasks in ``TASKS`` in ``K`` parallel processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_workers = 8\n",
      "Wall time: 4.3 s\n",
      "\n",
      "num_workers = 1\n",
      "Wall time: 6.31 s\n",
      "\n",
      "num_workers = 2\n",
      "Wall time: 4.89 s\n",
      "\n",
      "num_workers = 4\n",
      "Wall time: 3.77 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def parallel_solver_dask(alphas,betas,num_workers=2):\n",
    "\n",
    "    tasks = (dask.delayed(solver)(alpha,beta,gamma) for (alpha,beta,gamma) in zip(alphas,betas,gammas))\n",
    "    results = dask.compute(tasks,scheduler='processes',num_workers=num_workers)\n",
    "    \n",
    "    return [result.x for result in results[0]]\n",
    "    \n",
    "for num_workers in CPUs_list:\n",
    "    if num_workers > 36:\n",
    "        break\n",
    "    print(f'num_workers = {num_workers}')        \n",
    "    %time xopts = parallel_solver_dask(alphas,betas,num_workers=num_workers)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overhead:** dask does not work optimally in our situation (too large overhead), but it has other interesting features where it can be used on a cluster or to solve more complex problem (see below).\n",
    "\n",
    "[More on dask](http://docs.dask.org/en/latest/) ([examples](http://docs.dask.org/en/latest/delayed.html), [youtube tutorial](https://youtu.be/mqdglv9GnM8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some details on dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask can also handle algorithms, where only some parts can be done in parallel, while others must be done sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "def inc(x):\n",
    "    return x + 1\n",
    "\n",
    "def double(x):\n",
    "    return x + 2\n",
    "\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "data = [1, 2, 3, 4, 5]\n",
    "\n",
    "output = []\n",
    "for x in data:\n",
    "    a = inc(x)\n",
    "    b = double(x)\n",
    "    c = add(a, b)\n",
    "    output.append(c)\n",
    "\n",
    "total = sum(output)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "for x in data:\n",
    "    a = dask.delayed(inc)(x)\n",
    "    b = dask.delayed(double)(x)\n",
    "    c = dask.delayed(add)(a, b)\n",
    "    output.append(c)\n",
    "\n",
    "total = dask.delayed(sum)(output)\n",
    "print(total.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Pandas\"></a>\n",
    "\n",
    "# 7. Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a test dataset of $N$ units in $K$ groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.046466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.589362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.039398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.544107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0.073515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group     value\n",
       "0      0  0.046466\n",
       "1      5  0.589362\n",
       "2      3  0.039398\n",
       "3      0  0.544107\n",
       "4      8  0.073515"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_test_data(K,N):\n",
    "    np.random.seed(1986)\n",
    "    groups = np.random.randint(low=0,high=K,size=N)\n",
    "    values = np.random.uniform(size=N)\n",
    "    df = pd.DataFrame({'group':groups,'value':values})\n",
    "    return df\n",
    "\n",
    "K = 10\n",
    "N = 10**5\n",
    "df = create_test_data(K,N)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   group   100000 non-null  int32  \n",
      " 1   value   100000 non-null  float64\n",
      "dtypes: float64(1), int32(1)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Example 1: Capping values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A. Loops:** \n",
    "\n",
    "Use a **raw loop**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.48 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.100000\n",
       "1    0.589362\n",
       "2    0.100000\n",
       "3    0.544107\n",
       "4    0.100000\n",
       "Name: value, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loop(df):\n",
    "    result = df.value.copy()\n",
    "    for i in range(len(df)):\n",
    "        if df.loc[i,'value'] < 0.1:\n",
    "            result[i] = 0.1\n",
    "        elif df.loc[i,'value'] > 0.9:\n",
    "            result[i] = 0.9\n",
    "    return result\n",
    "\n",
    "%time loop(df)\n",
    "loop(df).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **apply row-by-row**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.2 ms ± 1.55 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.100000\n",
       "1    0.589362\n",
       "2    0.100000\n",
       "3    0.544107\n",
       "4    0.100000\n",
       "Name: value, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cap(value):\n",
    "    if value < 0.1:\n",
    "        return 0.1\n",
    "    elif value > 0.9:\n",
    "        return 0.9\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "# slower:\n",
    "# %time df.apply(lambda x: cap(x['value']),axis=1)\n",
    "\n",
    "%timeit df.value.apply(lambda x: cap(x))\n",
    "df.value.apply(lambda x: cap(x)).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B. Vectorization**: Avoid loop over rows.\n",
    "\n",
    "Use the **transform method**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.06 ms ± 586 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.100000\n",
       "1    0.589362\n",
       "2    0.100000\n",
       "3    0.544107\n",
       "4    0.100000\n",
       "Name: value, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cap_col(col):\n",
    "    result = col.copy()\n",
    "    I = result < 0.1\n",
    "    result[I] = 0.1\n",
    "    I = result > 0.9\n",
    "    result[I] = 0.9\n",
    "    return result\n",
    "\n",
    "# slower:\n",
    "# %timeit df.transform({'value':cap_col})\n",
    "\n",
    "%timeit df.value.transform(cap_col)\n",
    "df.value.transform(cap_col).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do it **manually**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.62 ms ± 128 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.100000\n",
       "1    0.589362\n",
       "2    0.100000\n",
       "3    0.544107\n",
       "4    0.100000\n",
       "Name: value, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit cap_col(df.value)\n",
    "cap_col(df.value).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do it **manually with a numpy array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "848 µs ± 76.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.100000\n",
       "1    0.589362\n",
       "2    0.100000\n",
       "3    0.544107\n",
       "4    0.100000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cap_col_np(col):\n",
    "    result = col.copy()\n",
    "    I = result < 0.1\n",
    "    result[I] = 0.1\n",
    "    I = result > 0.9\n",
    "    result[I] = 0.9\n",
    "    return result\n",
    "\n",
    "%timeit result = pd.Series(cap_col_np(df.value.values))\n",
    "pd.Series(cap_col_np(df.value.values)).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** The manual call of a numpy function is the fastest option.\n",
    "\n",
    "**Note:** The ``cap_col_np`` function could be speeded-up by numba just like any other function taking numpy inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "\n",
    "@nb.njit\n",
    "def cap_col_np_nb(col):\n",
    "    result = col.copy()\n",
    "    I = result < 0.1\n",
    "    result[I] = 0.1\n",
    "    I = result > 0.9\n",
    "    result[I] = 0.9\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.100000\n",
       "1    0.589362\n",
       "2    0.100000\n",
       "3    0.544107\n",
       "4    0.100000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@nb.njit\n",
    "def cap_col_np_nb(col):\n",
    "    result = col.copy()\n",
    "    I = result < 0.1\n",
    "    result[I] = 0.1\n",
    "    I = result > 0.9\n",
    "    result[I] = 0.9\n",
    "    return result\n",
    "\n",
    "pd.Series(cap_col_np_nb(df.value.values)).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606 µs ± 90.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit result = pd.Series(cap_col_np_nb(df.value.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Example 2: Demean within group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do it **manually:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.2 ms ± 5.54 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0   -0.458785\n",
       "1    0.090960\n",
       "2   -0.460590\n",
       "3    0.038856\n",
       "4   -0.425407\n",
       "Name: value, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def manually(df):\n",
    "    result = df.value.copy()\n",
    "    for group in range(K):\n",
    "        I = df.group == group\n",
    "        group_mean = df[I].value.mean()\n",
    "        result[I] = result[I]-group_mean\n",
    "    return result\n",
    "        \n",
    "%timeit result = manually(df)\n",
    "manually(df).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **groupby.agg** and **merge**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.4 ms ± 2.4 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0   -0.458785\n",
       "1    0.090960\n",
       "2   -0.460590\n",
       "3    0.038856\n",
       "4   -0.425407\n",
       "dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def demean_agg_merge(df):\n",
    "    \n",
    "    means = df.groupby('group').agg({'value':'mean'}).reset_index()\n",
    "    means = means.rename(columns={'value':'mean'})\n",
    "    \n",
    "    df_new = pd.merge(df,means,on='group',how='left')    \n",
    "    \n",
    "    return df_new['value'] - df_new['mean']\n",
    "\n",
    "%timeit demean_agg_merge(df)\n",
    "demean_agg_merge(df).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **groupby.value.apply**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.1 ms ± 664 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0   -0.458785\n",
       "1    0.090960\n",
       "2   -0.460590\n",
       "3    0.038856\n",
       "4   -0.425407\n",
       "Name: value, dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def demean_apply(df):\n",
    "    return df.groupby('group').value.apply(lambda x: x-x.mean())\n",
    "\n",
    "%timeit demean_apply(df)\n",
    "demean_apply(df).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **groupby.value.transform:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 ms ± 417 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0   -0.458785\n",
       "1    0.090960\n",
       "2   -0.460590\n",
       "3    0.038856\n",
       "4   -0.425407\n",
       "Name: value, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def demean_transform(df):\n",
    "    return df.groupby('group').value.transform(lambda x: x-x.mean())\n",
    "\n",
    "%timeit demean_transform(df)\n",
    "demean_transform(df).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **groupby.value.transform** with **built-in mean**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.75 ms ± 477 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0   -0.458785\n",
       "1    0.090960\n",
       "2   -0.460590\n",
       "3    0.038856\n",
       "4   -0.425407\n",
       "Name: value, dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def demean_transform_fast(df):\n",
    "    \n",
    "    means = df.groupby('group').value.transform('mean')\n",
    "    result = df.value - means\n",
    "    return result\n",
    "\n",
    "%timeit demean_transform_fast(df)\n",
    "demean_transform_fast(df).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** ``demean_transform_fast`` is the winner so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallization with dask and numba (+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a **bigger dataset** and set the index to group and sort by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.760289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.545587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.755536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.840404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.994973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          value\n",
       "group          \n",
       "0      0.760289\n",
       "0      0.545587\n",
       "0      0.755536\n",
       "0      0.840404\n",
       "0      0.994973"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 10\n",
    "N = 5*10**7\n",
    "df = create_test_data(K,N)\n",
    "df = df.set_index('group')\n",
    "df = df.sort_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 50000000 entries, 0 to 9\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   value   float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 762.9 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standard pandas:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.32 s\n",
      "Wall time: 1.34 s\n",
      "Wall time: 1.44 s\n",
      "Wall time: 8.14 s\n",
      "\n",
      "Wall time: 2.89 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "group\n",
       "0    0.260523\n",
       "0    0.045821\n",
       "0    0.255770\n",
       "0    0.340638\n",
       "0    0.495207\n",
       "Name: value, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time df.groupby('group').value.max()\n",
    "%time df.groupby('group').value.mean()\n",
    "%time df.groupby('group').value.sum()\n",
    "%time demean_apply(df)\n",
    "print('')\n",
    "%time demean_transform_fast(df)\n",
    "demean_transform_fast(df).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dask dataframe:** \n",
    "\n",
    "We can work with dask dataframes instead, which imply that some computations are done in parallel.\n",
    "\n",
    "The syntax is very similar to pandas, but far from all features are implemented (e.g. not transform). There are two central differences between dask dataframes and pandas dataframe:\n",
    "\n",
    "1. Dask dataframes are  divided into **partitions**, where each partitution is a sub-set of the index in the dataset. Computations can be done in parallel across partitions.\n",
    "2. Dask dataframes use **lazy evaluation**. Nothing is actually done before the ``.compute()`` method is called. \n",
    "\n",
    "The ``.compute()``  method returns a pandas series or dataframe. \n",
    "\n",
    "> **More info:** [documentation for dask.dataframe](http://docs.dask.org/en/latest/dataframe.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how **dask create partitions based on the index**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 2: (0, 5, 9)\n",
      "k = 5: (0, 2, 4, 6, 8, 9)\n",
      "k = 10: (0, 1, 2, 3, 4, 5, 6, 7, 8, 9)\n"
     ]
    }
   ],
   "source": [
    "for k in [2,5,10]:\n",
    "    ddf = dd.from_pandas(df, npartitions=k)\n",
    "    print(f'k = {k}:',ddf.divisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time gains are, however, very modest, if there at all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of partitions = 1\n",
      "Wall time: 792 ms\n",
      "\n",
      "Wall time: 1.22 s\n",
      "Wall time: 3.48 s\n",
      "Wall time: 1.42 s\n",
      "Wall time: 5.65 s\n",
      "\n",
      "number of partitions = 10\n",
      "Wall time: 9.25 s\n",
      "\n",
      "Wall time: 782 ms\n",
      "Wall time: 1.95 s\n",
      "Wall time: 883 ms\n",
      "Wall time: 4.26 s\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "group\n",
       "0    0.260523\n",
       "0    0.045821\n",
       "0    0.255770\n",
       "0    0.340638\n",
       "0    0.495207\n",
       "Name: value, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def demean_apply_dd(dff):\n",
    "    result = dff.groupby('group').value.apply(lambda x: x-x.mean(), meta=('value','float64'))\n",
    "    return result.compute()\n",
    "\n",
    "for k in [1,K]:\n",
    "    \n",
    "    print(f'number of partitions = {k}')\n",
    "    %time ddf = dd.from_pandas(df, npartitions=k)\n",
    "    print('')\n",
    "    \n",
    "    %time ddf.groupby('group').value.max().compute()\n",
    "    %time ddf.groupby('group').value.mean().compute()\n",
    "    %time ddf.groupby('group').value.sum().compute()  \n",
    "    %time demean_apply_dd(ddf)\n",
    "    print('')\n",
    "    \n",
    "demean_apply_dd(ddf).head()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** Some computations are faster after the partioning (not on all computers though). The missing speed-up is most likely explained by fetching of memory being the bottleneck rather than performing the calculations. Generally, the size and complexity of the problem and how many CPUs you have will determine how large the is benefit is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numba:** Handwritten numba functions for each task can also provide a speed-up in some cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.97 s\n",
      "Wall time: 1.97 s\n",
      "Wall time: 1.86 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.260523\n",
       "1    0.045821\n",
       "2    0.255770\n",
       "3    0.340638\n",
       "4    0.495207\n",
       "dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@nb.njit(parallel=True)\n",
    "def groupby_demean_numba(group,value,K):\n",
    "    \n",
    "    result = np.zeros(value.size)\n",
    "    for i in nb.prange(K):\n",
    "        I = group == i\n",
    "        mean = np.mean(value[I])\n",
    "        result[I] = value[I]-mean\n",
    "    \n",
    "    return result\n",
    "\n",
    "for _ in range(3):\n",
    "    %time result = pd.Series(groupby_demean_numba(df.index.values,df.value.values,K))\n",
    "\n",
    "pd.Series(groupby_demean_numba(df.index.values,df.value.values,K)).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** The speed-up is modest. Again the size and complexity of the problem and how many CPUs you have will determine how large the benefit is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Summary\"></a>\n",
    "\n",
    "# 8. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This lecture:** You learned that optimizing performance is a difficult task, but the recommendation is to follow the following 6-step procedure:\n",
    "\n",
    "1. Choose the **right algorithm**\n",
    "2. Implement **simple and robust code** for the algorithm \n",
    "3. Profile the code to **find bottlenecks**\n",
    "4. Use **precomputations**, **comphrensions** and **vectorization** to speed-up the code\n",
    "5. Still need more speed? Consider **numba**, **joblib** or **dask**\n",
    "6. Still not enough? **C++** is the next level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next lecture:** Perspectives on other programming languages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
